{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_80688\\238809324.py:1: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_metadata = pd.read_csv('Dataset/movies_metadata.csv')\n"
     ]
    }
   ],
   "source": [
    "movies_metadata = pd.read_csv('Dataset/movies_metadata.csv')\n",
    "ratings = pd.read_csv('Dataset/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been processed and saved to Dataset/recommendations.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_7616\\2396732515.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  recommendations_df = pd.concat([recommendations_df, filtered_ratings_df[['userId', 'user_rating']]], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read ratings.csv\n",
    "ratings_df = pd.read_csv('Dataset/ratings.csv')\n",
    "\n",
    "# Filter rows where userId is less than or equal to 100\n",
    "filtered_ratings_df = ratings_df[ratings_df['userId'] <= 100].copy()\n",
    "\n",
    "# Rename the 'rating' column to 'user_rating'\n",
    "filtered_ratings_df.rename(columns={'rating': 'user_rating'}, inplace=True)\n",
    "\n",
    "# Create or read Dataset/recommendations.csv\n",
    "recommendations_file_path = 'Dataset/recommendations.csv'\n",
    "try:\n",
    "    recommendations_df = pd.read_csv(recommendations_file_path)\n",
    "except FileNotFoundError:\n",
    "    # If recommendations.csv doesn't exist, create an empty DataFrame\n",
    "    recommendations_df = pd.DataFrame(columns=['userId', 'user_rating'])\n",
    "\n",
    "# Add 'userId' and 'user_rating' columns to recommendations.csv\n",
    "recommendations_df = pd.concat([recommendations_df, filtered_ratings_df[['userId', 'user_rating']]], ignore_index=True)\n",
    "\n",
    "# Save the updated Dataset/recommendations.csv\n",
    "recommendations_df.to_csv(recommendations_file_path, index=False)\n",
    "\n",
    "print(\"Data has been processed and saved to Dataset/recommendations.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_7616\\1795220442.py:7: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_metadata_df = pd.read_csv('Dataset/movies_metadata.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been processed and saved to Dataset/recommendations.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read recommendations.csv\n",
    "recommendations_df = pd.read_csv('Dataset/recommendations.csv')\n",
    "\n",
    "# Read movies_metadata.csv\n",
    "movies_metadata_df = pd.read_csv('Dataset/movies_metadata.csv')\n",
    "\n",
    "# Iterate over unique userIds\n",
    "for user_id in range(1, 101):\n",
    "    # Calculate the count for the current userId\n",
    "    count = recommendations_df[recommendations_df['userId'] == user_id].shape[0]\n",
    "\n",
    "    # Fetch the corresponding unique movie IDs from movies_metadata.csv\n",
    "    unique_movie_ids = movies_metadata_df['id'].sample(n=count, random_state=42).tolist()\n",
    "\n",
    "    # Fetch relevant information for each movie ID\n",
    "    movie_info_df = movies_metadata_df[movies_metadata_df['id'].isin(unique_movie_ids)][['id', 'genres', 'title', 'overview', 'poster_path', 'vote_average', 'tagline', 'runtime']]\n",
    "\n",
    "    # Rename the 'id' column to 'movie_id'\n",
    "    movie_info_df.rename(columns={'id': 'movie_id'}, inplace=True)\n",
    "\n",
    "    # Create a DataFrame with repeated userId values\n",
    "    user_id_df = pd.DataFrame({'userId': [user_id] * count})\n",
    "\n",
    "    # Merge user_id_df with movie_info_df on the 'userId' column\n",
    "    user_recommendations_df = pd.merge(user_id_df, movie_info_df, how='cross')\n",
    "\n",
    "    # Append the new user recommendations to the main recommendations DataFrame\n",
    "    recommendations_df = pd.concat([recommendations_df, user_recommendations_df], ignore_index=True)\n",
    "\n",
    "# Save the updated recommendations.csv\n",
    "recommendations_df.to_csv('Dataset/recommendations.csv', index=False)\n",
    "\n",
    "print(\"Data has been processed and saved to Dataset/recommendations.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been filtered and saved to Dataset/recommendations_filtered.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read recommendations.csv\n",
    "recommendations_df = pd.read_csv('Dataset/recommendations.csv')\n",
    "\n",
    "# Drop rows where userId is greater than 10\n",
    "filtered_recommendations_df = recommendations_df[recommendations_df['userId'] <= 10]\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file or overwrite the existing recommendations.csv\n",
    "filtered_recommendations_df.to_csv('Dataset/recommendations_filtered.csv', index=False)\n",
    "\n",
    "print(\"Data has been filtered and saved to Dataset/recommendations_filtered.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Generated Hyperlinks by appending path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            poster_path  \\\n",
      "0      /eREsgaAN2Br1Tlg9eDSBjHrb1AC.jpg   \n",
      "1      /vIIMwG7d353nTKxt5RkxAzqIPrH.jpg   \n",
      "2      /nZ7UYOQ50C38wdWqOcNxCxZ6GB1.jpg   \n",
      "3      /wRYFf3o6JP4ezL5Ci8yF8m7EHf6.jpg   \n",
      "4      /oe8VjWCKXktqA19T1ZWtaSn8rc2.jpg   \n",
      "...                                 ...   \n",
      "87869  /3pMUkJuNNtAhZM8VxULNWAGuXh0.jpg   \n",
      "87870  /biDncjUHbji0dknCONmaXKY6OPw.jpg   \n",
      "87871  /8H9hz3fsJpQsY5lUDloCWOuwoTW.jpg   \n",
      "87872  /z7jmLmrs0pLlDU4GI6ItaJeqlET.jpg   \n",
      "87873  /kZuoSBMJzkl9cQ6OPQpqqkTjf4W.jpg   \n",
      "\n",
      "                                              hyperlinks  \n",
      "0      https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "1      https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "2      https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "3      https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "4      https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "...                                                  ...  \n",
      "87869  https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "87870  https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "87871  https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "87872  https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "87873  https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "\n",
      "[87874 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load recommendations.csv\n",
    "recommendations = pd.read_csv('Dataset/recommendations.csv')\n",
    "\n",
    "# Add a new 'hyperlinks' column\n",
    "base_url = 'https://flixpatrol.com/runtime/cache/files/posters/e/w350/'\n",
    "recommendations['hyperlinks'] = base_url + recommendations['poster_path']\n",
    "\n",
    "# Display the dataframe with the new 'hyperlinks' column\n",
    "print(recommendations[['poster_path', 'hyperlinks']])\n",
    "\n",
    "# Save the modified dataframe to the same CSV file\n",
    "recommendations.to_csv('Dataset/recommendations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Merged Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been updated and saved to Dataset/recommendations_updated.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read recommendations.csv\n",
    "recommendations_df = pd.read_csv('Dataset/recommendations.csv')\n",
    "\n",
    "# Function to add genres information where 'genres' is empty\n",
    "def add_default_genres(row):\n",
    "    if pd.isnull(row['genres']) or row['genres'] == '[]':\n",
    "        return \"[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'name': 'Drama'}]\"\n",
    "    else:\n",
    "        return row['genres']\n",
    "\n",
    "# Apply the function to the 'genres' column\n",
    "recommendations_df['genres'] = recommendations_df.apply(add_default_genres, axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file or overwrite the existing recommendations.csv\n",
    "recommendations_df.to_csv('Dataset/recommendations_updated.csv', index=False)\n",
    "\n",
    "print(\"Data has been updated and saved to Dataset/recommendations_updated.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Added default placeholder poster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been updated and saved to Dataset/recommendations_final.csv.\n"
     ]
    }
   ],
   "source": [
    "# Hyperlink to be added for blank cells\n",
    "default_hyperlink = \"https://media.officedepot.com/images/f_auto,q_auto,e_sharpen/products/951851/951851_o02_112520/951851\"\n",
    "\n",
    "# Function to add default hyperlink where 'hyperlinks' is empty\n",
    "def add_default_hyperlink(row):\n",
    "    if pd.isnull(row['hyperlinks']) or row['hyperlinks'].strip() == '':\n",
    "        return default_hyperlink\n",
    "    else:\n",
    "        return row['hyperlinks']\n",
    "\n",
    "# Apply the function to the 'hyperlinks' column\n",
    "recommendations_df['hyperlinks'] = recommendations_df.apply(add_default_hyperlink, axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file or overwrite the existing recommendations.csv\n",
    "recommendations_df.to_csv('Dataset/recommendations_final.csv', index=False)\n",
    "\n",
    "print(\"Data has been updated and saved to Dataset/recommendations_final.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Formatted and made Genre list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  genres  \\\n",
      "0      [{'id': 18, 'name': 'Drama'}, {'id': 36, 'name...   \n",
      "1      [{'id': 80, 'name': 'Crime'}, {'id': 53, 'name...   \n",
      "2      [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...   \n",
      "3      [{'id': 10770, 'name': 'TV Movie'}, {'id': 18,...   \n",
      "4      [{'id': 80, 'name': 'Crime'}, {'id': 18, 'name...   \n",
      "...                                                  ...   \n",
      "87869  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
      "87870  [{'id': 10749, 'name': 'Romance'}, {'id': 1040...   \n",
      "87871  [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...   \n",
      "87872  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name...   \n",
      "87873  [{'id': 10749, 'name': 'Romance'}, {'id': 18, ...   \n",
      "\n",
      "                            genres_list  \n",
      "0                      [Drama, History]  \n",
      "1              [Crime, Thriller, Drama]  \n",
      "2                      [Drama, Romance]  \n",
      "3                     [TV Movie, Drama]  \n",
      "4                        [Crime, Drama]  \n",
      "...                                 ...  \n",
      "87869                   [Comedy, Drama]  \n",
      "87870           [Romance, Music, Drama]  \n",
      "87871                  [Drama, Romance]  \n",
      "87872  [Drama, Comedy, Thriller, Crime]  \n",
      "87873                  [Romance, Drama]  \n",
      "\n",
      "[87874 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "# Load recommendations.csv\n",
    "recommendations = pd.read_csv('Dataset/recommendations.csv')\n",
    "\n",
    "# Function to extract genres from the 'genres' column\n",
    "def extract_genres(genres_str):\n",
    "    genres_list = ast.literal_eval(genres_str)\n",
    "    return [genre['name'] for genre in genres_list]\n",
    "\n",
    "# Create a new 'genres_list' column\n",
    "recommendations['genres_list'] = recommendations['genres'].apply(extract_genres)\n",
    "\n",
    "# Display the dataframe with the new 'genres_list' column\n",
    "print(recommendations[['genres', 'genres_list']])\n",
    "\n",
    "# Save the modified dataframe to the same CSV file\n",
    "recommendations.to_csv('Dataset/recommendations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Added ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been updated with random ratings and saved to Dataset/recommendations_final_random.csv.\n"
     ]
    }
   ],
   "source": [
    "# Function to randomly add values to 'user_rating' column\n",
    "def add_random_ratings(row):\n",
    "    if pd.isnull(row['user_rating']):\n",
    "        return np.random.choice([1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5])\n",
    "    else:\n",
    "        return row['user_rating']\n",
    "\n",
    "# Apply the function to the 'user_rating' column\n",
    "recommendations_df['user_rating'] = recommendations_df.apply(add_random_ratings, axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file or overwrite the existing recommendations.csv\n",
    "recommendations_df.to_csv('Dataset/recommendations_final_random.csv', index=False)\n",
    "\n",
    "print(\"Data has been updated with random ratings and saved to Dataset/recommendations_final_random.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Nan Values in Taglines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in the 'tagline' column have been replaced and the DataFrame has been updated in recommendations.csv.\n"
     ]
    }
   ],
   "source": [
    "# Load the recommendations.csv file into a DataFrame\n",
    "df = pd.read_csv(\"Dataset/recommendations.csv\")\n",
    "\n",
    "# Replace NaN values in the \"tagline\" column with a default value (you can change it to your preferred replacement)\n",
    "default_tagline = \"None\"\n",
    "df['tagline'] = df['tagline'].fillna(default_tagline)\n",
    "\n",
    "# Save the updated DataFrame back to the recommendations.csv file\n",
    "df.to_csv(\"Dataset/recommendations.csv\", index=False)\n",
    "\n",
    "# Print a message indicating that NaN values in the \"tagline\" column have been replaced\n",
    "print(\"NaN values in the 'tagline' column have been replaced and the DataFrame has been updated in recommendations.csv.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
